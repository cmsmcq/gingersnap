# Generating infinite series of regular subset and superset approximations for context-free languages

2020-01-11

This document describes a method for generating an infinite series of
pairs of regular approximations for a given context free language *L*
defined by a context free grammar *G*.  It is currently rather terse,
because I'm in a hurry.

## The pumping lemma for regular languages

An important result in formal language theory is that for any regular
language *L* there exists a number *m* such that any sentence *s*
in *L* of length greater than *m* can be partitioned into
substrings *u*, *v*, and *w* such that

* *v* is non-empty (though *u* and *w* may be)
* |*u* *w*| <= *m*
* *s* = *u* *v* *w*
* for all integers *n* >= 0, the string *u* *v*<sup>*n*</sup> *w* is in *L*

(I am using blank as a concatenation operator here.)

(I am also quoting from memory, so if the reader wants to be
absolutely sure of the details, the reader should check a book on
automata theory.  The fact that without *v* the sentence is shorter
than *m* symbols long and with *v* it's not appears to be important
for some proofs; it's not important for my purposes.)

### The pumping lemma and walking through the FSA 

One way to prove the lemma involves thinking about the states in a
deterministic FSA recognizing *L*. Since *L* is regular, such an FSA
is guaranteed to exist. (Not only that, but there are algorithms to
reduces the number of states in the FSA to the minimum needed to
recognize *L*.) Each sentence *s* in *L* can be associated with a walk
through the FSA which leads from the start state to some final state,
traversing one transition arc per symbol in *s*.

(I am using *walk*, not *path*, because in graph theory a path has
restrictions I don't want.)

Now, if *s* has more symbols than the FSA has states, it's clear that
at some point in the walk some state *r* is visited for the second
time.

So there must be a cycle in the FSA. (If there is no cycle in the FSA,
there will be a maximum length to sentences in *L* and only a finite
number of sentences. The pumping lemma is vacuously true if we set *m*
to the maximum length of sentences in *L*.)

To make the statements in the lemma true, we let

* *u* = the string that gets us from the start state to (the first visit to) *r*
* *v* = the string that gets us from the first visit to *r* to the second visit to *r*
* *w* = the string that gets us from the second visit to *r* to some final state

It's clear that *u* *w* (= *u* *v*<sup>0</sup> *w*) has a walk that goes from  
the start state to a final state, so it must be in *L*.

We know from the givens that *u* *v* *w* (= *u* *v*<sup>1</sup> *w*) is in *L*.

And it's obvious that if we can go from around the cycle from
state *r* back to state *r* once, we can do it as many times as we
like. That gives us *u* *v*<sup>*n*</sup> *w* for *n* > 1.

The metaphoric image of going around and around the cycle to pump more
and more characters into a sentence being generated gives rise to the
name "pumping lemma". Those who dislike metaphor call it the *uvw*
lemma instead.

### The pumping lemma and the parse trees of a regular grammar

An FSA can be regarded as just a visualization of a regular grammar,
that is a grammar in which every production rule has one of the forms

* N: T, N2.
* N: {nil} N2.
* N: {nil}.

where *N* and *N2* are nonterminal symbols and *T* is a terminal
symbol. For each state in the FSA, we have a nonterminal. The first
rule form corresponds to a transition from state *N* to state *N2* on
terminal symbol *T*; the second corresponds to an empty transition
(epsilon transition) from *N* to *N2*. The third rule form marks *N*
as a final state.

(Some authors allow rules of the form

* N: T.

and disallow the third form, but then the 1:1 correspondence of FSA
states and nonterminals falls apart.)

Each walk through the FSA from start state to some final state
corresponds to a parse tree. Each state that is visited more than once
in the course of such a walk corresponds to a recursive nonterminal
which appears more than once in the parse tree, on nodes which are in
an ancestor/descendant relation.

If the recursive nonterminal is *r*, then

* *u* = the string generated by the nodes from the root of the parse tree to the topmost occurrence of *r*
* *v* = the string generated by the topmost *r* and its descendants down to but not including the lower *r*
* *w* = the string generated by the lower *r* and all of its descendants in the parse tree

When there is a cycle in the FSA from state *r* to state *r*, then the
nonterminal *r* can derive a sentential form containing the
nonterminal *r* (which is what I mean when I say *r* is recursive).

Just as we can walk the cycle zero times, once, or more than once, so
the topmost *r* in a parse tree can have no *r* nodes among its
descendants, or one, or more than one.


## The pumping lemma for context-free languages

Like the regular languages, the context-free languages also have a
pumping lemma. It says that for any context-free language *L* there
exists a number *m* such that any sentence *s* in *L* of length
greater than *m* can be partitioned into
substrings *u*, *v*, *w*, *x*, and *y* such that

* *v* *x* is non-empty 
* *s* = *u* *v* *w* *x* *y*
* for all integers *n* >= 0, the
string *u* *v*<sup>*n*</sup> *w* *x*<sup>*n*</sup> *y* is in *L*
* |*s*| >= *m*
* |*u* *w* *y*| < *m*

Here, as above, the observations about the length of the sentence with
and without the repeatable substrings are not important for our
purposes. Any sentence for which the first three conditions are
satisifed I will call a *pumpable* sentence. (It can occur that there
are pumpable sentences shorter than the *m* for a given language. I
don't care about *m*, I only care about the first three properties.

Note that if either *v* or *x* is empty, this reduces to the pumping
lemma for regular languages: the sentence has a prefix, a non-empty
repeatable substring, and a suffix. If both *v* and *x* are non-empty,
then the language is non-regular.

A simple example is given by the grammar

    S: 'a'; '(', S, ')'.

which defines the language *L* whose sentences all have one occurrence
of the letter 'a' surrounded by zero or more pairs of matching
parentheses. The sentence "(a)" can be divided into

* *u* = '' (empty string) 
* *v* = '(' 
* *w* = 'a'
* *x* = ')'
* *y* = '' (empty string) 

and indeed for all *n* >= 0, *u* *v*<sup>*n*</sup> *w* *x*<sup>*n*</sup> *y* is in *L*.

Any strings that can play the role of *v* or *x* in a pumpable
sentence I will call *brackets*. When both *v* and *x* are non-empty,
they form *matching brackets* or a *bracket pair*.

Note that while typographic brackets like the parentheses in the
grammar just shown form a convenient example, not all grammatical
brackets are typographic brackets: in a language like Pascal, the
keywords `begin` and `end` are gramatically speaking brackets: in any
syntactically correct Pascal program they must pair up correctly.

From time to time, it may be convenient to use the term *bracket* not
just for the terminal sequences *v* and *x* but for the sequences of
symbols which generate *v* and *x*. That is, the term *bracket* is not
restricted to sequences of terminal symbols.

Informally, the pumping lemma can be said to capture the requirement
that in a non-regular context free language, a parser must keep track
of the number and type of unmatched left brackets and pair them up
correctly with their matching right brackets.


## The pumping lemma and parse trees

One way to understand why the pumping lemma holds is to consider parse
trees in which some recursive nonterminal *r* occurs both as an
ancestor and as a descendant. A drawing of the tree would be
convenient, but for now I'll attempt to make things clear by talking
about sentential forms. If an *r* appears in a parse tree at all, then
it must be the case that the start symbol of the grammar generates
some sentential form (alpha, *r*, zeta), where alpha and zeta are
sequences of symbols (arbitrary mixes of terminal and non-terminal)

* S =>* alpha *r* zeta

or, with real Greek symbols (if it works):

* S ⇒* α *r* ζ (i.e. alpha, *r*, zeta) 

If an ancestor/descendant pair of nodes both labeled *r* appear in a
parse tree, then it must be the case that *r* generates some sequence
of symbols

* *r* =>* beta *r* delta, or 
* *r* ⇒* β *r* δ 

And if some *r* is the bottom-most *r* in a parse tree, then it must
be the case that *r* generates some sequence of symbols gamma that
does not include *r*.

* *r* =>* gamma
* *r* ⇒* γ

Putting these all together, we have

* S ⇒* α β γ δ ζ

Further generation steps will turn each of these subsequences into
sequences of terminal symbols *u* *v* *w* *x* *y*.

Note also that if *r* generates the form beta *r* delta

* *r* ⇒* β *r* δ 

then repeating the same derivation steps we can get 

* *r* ⇒* β β *r* δ δ 
* *r* ⇒* β β β *r* δ δ δ 
* etc.

In fact, what we have is that for all *n* >= 1,

* *r* ⇒* β<sup>*n*</sup> *r* δ<sup>*n*</sup>

And since *r* also derives gamma, we have for *n* >= 0

* *r* ⇒* β<sup>*n*</sup> γ δ<sup>*n*</sup>

So (skipping over some bookkeeping) we can see that if the derivation
relations mentioned hold and α β γ δ ζ is a sentential form (i.e. it
generates a sentence in *L(G)*), then for all *n* >= 0,

* α β<sup>*n*</sup> γ δ<sup>*n*</sup> ζ is a sentential form.

When neither beta nor delta generate the empty string, they form a
bracket pair. (When one or both generate both the empty string and
some non-empty string, I find it easy to get confused, but I think
that there, too, they form a bracket pair.)

## Regular approximations and the pumping lemmas

Given a pumpable sentence *s* in some non-regular context-free
language *L*, with the properties that

* neither *v* nor*x* is empty 
* *s* = *u* *v* *w* *x* *y*
* for all integers *n* >= 0, the
string *u* *v*<sup>*n*</sup> *w* *x*<sup>*n*</sup> *y* is in *L*

What keeps *L* from being regular is, informally, the requirement
that *v* and *x* occur the same number of times, from zero up.

### Approximation with a subset 

We could make *L* regular (or, more precisely, we could construct a
regular approximation of *L*) if we limited *n* to some finite number *k*.
The language consisting of the letter 'a' wrapped in matching
parentheses up to a maximum depth of 2 is clearly regular:

    S: 'a'; '(a)'; '((a))'.

If we choose a higher value for *k*, the approximation becomes better
in the sense that it includes more and more sentences in *L* without
losing any that were accepted for lower *k*. There is no limit to *k*,
and thus no limit to our ability to improve our approximation. (Or to
put it negatively: there is no 'best' regular subset approximating a
non-regular context-free language *L*.)

So given a context-free language *G*, a simple way to create a regular
subset approximation for *L(G)* is to limit the nesting depth for
brackets. Some complications can arise, which are here passed over in
silence.

Informally, such subsets can be said to require a parser to keep track
of the number and type of unmatched left brackets and pair them up
correctly with their matching right brackets, but only up to some
given finite maximum depth *k*.

Since subsets do not generate all the sentences of the target 
language, they can be said to 'under-generate'. We refer to a subset 
for a given *k* as *U(k)*.   (Note:  in some older materials and in some
program names, the terms *r*<sub>*k*</sub> or *r_k* or *rk* may
be used instead.)


### Approximation with a superset

Another way to make a regular approximation for *L* is to de-couple
the exponents of *v* and *x*, and define the language that includes
every sentence in *L* and also, for each pumpable sentence *s* in *L*,
all sentences of the
form *u* *v*<sup>*n*</sup> *w* *x*<sup>*m*</sup> *y*, for *n*, *m* >=
0. Since *n* and *m* are decoupled, we can hold either constant while
varying the other, which means the language will satisfy the pumping
lemma for regular languages.

Informally, this approximation can be said to require a parser to keep
track of where brackets can appear, but to allow it to lose track of
the number and type of brackets, since they do not need to be paired
up in left/right pairs.

We can make a smaller superset by imposing some restrictions on *n*
and *m*. For example, we can say for some positive integer *k*

* for all integers *n*, *m* >= 0, the
string *u* *v*<sup>*n*</sup> *w* *x*<sup>*m*</sup> *y* is in *L* if either:

    * *n* = *m* and *n* <= *k*
    * *n* > *k*, *m* > *k*

Informally, such approximations can be thought of as requiring a
parser to keep track of unmatched left brackets up to the given
depth *k*, but then allow it to lose track of brackets, as long as the
outermost *k* brackets do match up correctly.

Since supersets generate some sentences not in the target 
language, they can be said to 'over-generate'. We refer to a subset 
for a given *k* as *O(k)*.   (Note:  in some older materials and in some
program names, the terms *R*<sub>*k*</sub> or *R_k* or *Rk* may
be used instead.)


## Operating on the grammar

### Generating U(k) subsets 

Given a context-free grammar *G*, we can generate a grammar for the
subset *U(k)* by rewriting the grammar to keep track (in affixes) of
the derivation path from the start symbol downwards (or equivalently:
the current parse stack).

For the example grammar given above, the rule is first rewritten as

    S: 'a'; '(', S.S, ')'.

The nonterminal *S.S* denotes "an *S* with one *S* as ancestor". It
can be defined by rewriting the original rule:

    S.S: 'a'; '(', S.S.S, ')'.

And so on. Each time S is called recursively, another ".S" is appended
to the name.

The parameter *k* specifies how many ancestors a nonterminal in a
derivation tree is allowed to have with the same name. Note that if
there is one ancestor of the same name in the derivation tree, there
will be one occurrence of the beta/delta bracket pair for the
nonterminal in question.

If *k* = 0, then no recursive references to any nonterminal are
allowed, and the nonterminal *S.S* is left undefined. That makes the
second right-hand side of *S* unsatisfiable, and the grammar can then
be simplified to:

    S: 'a'.

If *k* = 2, then the grammar becomes:

    S: 'a'; '(', S.S, ')'.
    S.S: 'a'; '(', S.S.S, ')'. 
    S.S.S: 'a'; '(', S.S.S.S, ')'. 
    { S.S.S.S is undefined. }

After simplification, this becomes

    S: 'a'; '(', S.S, ')'.
    S.S: 'a'; '(', S.S.S, ')'. 
    S.S.S: 'a'.

Since there are no recursive nonterminals in the grammar, each
reference to a nonterminal can be replaced by its definition to
produce a single regular expression defining the language.

In this example there is only one nonterminal in the original grammar
and therefore only one nonterminal appears in the affixes depicting
the stack; in the general case there may be many different symbols.
The initial part of the nonterminal symbol indicates the 'base symbol'
of the rule: the nonterminal in the original grammar from which the
suffixed nonterminal derives.

### Generating the O(0) superset

One way to generate the *O(0)* superset from the grammar *G* is as
follows. I oversimplify slightly.

First, from *G*, generate a pushdown automaton:

1. Generate a set of finite-state automata, one for each nonterminal.
Without loss of generality, the description below assumes that
each such FSA has a single final state.

2. In these FSAs, replace every transition on a nonterminal *N* from
state *q* to state *r* with

    * an epsilon transition from *q* to the start state for *N*, 
    coupled with the instruction to push state *r* on the stack

    * an epsilon transition from the final state for *N* to state *r*,
    coupled with the instruction to pop state *r* from the stack
	(so that transition can only be used if *r* is on top of the
	stack)
	
Second, from this pushdown automaton derive a conventional FSA by
erasing all reference to the stack. The main consequence of this is
that the epsilon transitions introduced in the pushdown automaton are
no longer conditional on the state of the stack.

Informally, the FSA so generated preserves all the constraints of the
grammar except those that require the use of a pushdown stack.

The description just given glosses over a couple of points that are
important in practice.

* First, some bookkeeping is necessary to ensure that the pushdown
automaton and the FSA have the proper start states and final states.

* Second, to make the FSA preserve as much of the grammar as possible,
non-recursive nonterminals which define regular languages are better
treated as if they were terminals: arcs for such pseudo-terminals
should not be replaced by epsilon transitions to and from the FSA for
the pseudo-terminal. (Equivalently: replace references to such
pseudo-terminals with their definitions, repeatedly, until there are
no non-recursive nonterminals left in the grammar, and *then* generate
the pushdown automaton and the FSA.)

I believe it is possible to construct a proof that the pushdown
automaton described informally above recognizes *L(G)*, but I offer no
proof sketch here.

For the simple grammar given above, the *O(0)* pushdown automaton has
a form like the following.  Stack instructions associated with a rule are
delimited here by {⥮ and ⥯}; the only stack instructions are push and pop.

    { S: 'a'; '(', S, ')'.  }

    S = {nil} S_0 {⥮ push extcall_S ⥯}.
    S_0 = 'a', S_1 ; '(', S_2.
    S_1 = {nil} S_f.
    S_2 = {nil} S_0{⥮ push S_3 ⥯}.
    S_3 = ')', S_4.
    S_4 = {nil} S_f.
    S_f = {nil} S_3{⥮ pop S_3 ⥯} ; {nil} {⥮ pop extcall_S ⥯}.

The rule for *S* and the final rule for *S_f* are the bookkeeping
rules mentioned above.

The FSA is exactly the same, except that the stack instructions are
deleted. If the regular grammar for the FSA is simplified
appropriately, it eventually reduces to the regular expression

    S = '('*, 'a', ')'*.


### Generating the O(k) supersets for k > 0

The *O(k)* superset for a grammar *G* can be defined by a fairly
simple process.

* Generate the *O(0)* superset grammar for *G*. 

* Generate the *U(k)* subset grammar for *G*. Do not simplify by 
removing references to undefined nonterminals. 

* For each undefined nonterminal whose base symbol is *N*, extract
an *O(0)* regular approximation for *N* from the *O(0)* superset
grammar of step 1. This may involve some rewriting to avoid name
conflicts and some bookkeeping rules to ensure that the starting and
final states for *N* are treated properly. Use that regular
approximation of *N* as a definition for the undefined nonterminal
whose base symbol is *N*.

For the example grammar, the *O(0)* superset grammar and the *U(2)*
subset grammar have already been shown. Knitting them together
involves nothing more than supplying a definition for the
nonterminal *S.S.S.S*.

    S: 'a'; '(', S.S, ')'.
    S.S: 'a'; '(', S.S.S, ')'. 
    S.S.S: 'a'; '(', S.S.S.S, ')'. 
    S.S.S.S: '('*, 'a', ')'*.

Like others exhibited before, this grammar may be seen to define a
regular language because it has no recursive nonterminals. It can thus
be reduced to a single regular expression.

Informally, this grammar defines the set of strings consisting of the
letter 'a' surrounded by parentheses, with the proviso that the two
outer parentheses must match and that if there are more than two
levels of parentheses, the additional ones need not match up properly.
But the grammar does still enforce the rule that left parenthesis is
allowed only before the 'a', right parenthesis only after it.


## Summary

For any non-negative integer k, we can generate a subset *U(k)* and a
superset *O(k)*, with the properties that

* *U(k)* contains all the sentences of *L* such that no matching
brackets nest more than *k* levels deep.

* *O(k)* contains both *U(k)* and also sentences in which brackets may
occur more than *k* levels deep but are not guaranteed to match at
those deeper levels.

So*U(0)* contains the sentences of *L* with no brackets, *U(1)* the
sentences of *L* with brackets occurring at most one level deep (no
nesting), *U(2)* sentences with at most two levels of brackets. And
analogously, *O(0)* contains all the sentences of *L*, and in addition
sentences with missing or extra brackets, *O(1)* removes from *O(0)*
all sentences in which outermost brackets fail to match,*O(2)* removes
all sentences in which brackets at levels 1 or 2 fail to match, and so
on.

## Related documents

*Need a bibliography here, perhaps, or a pointer to one.*

